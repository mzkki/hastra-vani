{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main model (adjusting for the 28x28 image input size)\n",
    "loaded_model = tf.keras.models.load_model(\"../notebook/best_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter for each letter A-Z\n",
    "ct = {chr(i): 0 for i in range(65, 91)}\n",
    "blank_flag = 0\n",
    "current_symbol = \"Empty\"\n",
    "word = \"\"\n",
    "str_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Prediction\")\n",
    "panel = tk.Label(root)\n",
    "panel.pack(padx=10, pady=10)\n",
    "panel2 = tk.Label(root)\n",
    "panel2.pack(padx=10, pady=10)\n",
    "T = tk.Label(root)\n",
    "T.pack()\n",
    "panel3 = tk.Label(root)\n",
    "panel3.pack(padx=10, pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Too early to create image: no default root window",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 90\u001b[0m\n\u001b[0;32m     86\u001b[0m         panel\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m img_tk  \u001b[38;5;66;03m# Keep a reference to avoid garbage collection\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     root\u001b[38;5;241m.\u001b[39mafter(\u001b[38;5;241m10\u001b[39m, update_frame)  \u001b[38;5;66;03m# Schedule next frame update\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[43mupdate_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Release the video capture object and close all OpenCV windows\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 83\u001b[0m, in \u001b[0;36mupdate_frame\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[0;32m     82\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m---> 83\u001b[0m img_tk \u001b[38;5;241m=\u001b[39m \u001b[43mImageTk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPhotoImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m panel\u001b[38;5;241m.\u001b[39mconfig(image\u001b[38;5;241m=\u001b[39mimg_tk)\n\u001b[0;32m     86\u001b[0m panel\u001b[38;5;241m.\u001b[39mimage \u001b[38;5;241m=\u001b[39m img_tk  \u001b[38;5;66;03m# Keep a reference to avoid garbage collection\u001b[39;00m\n",
      "File \u001b[1;32mc:\\HASTRA_VANI\\myenv\\Lib\\site-packages\\PIL\\ImageTk.py:128\u001b[0m, in \u001b[0;36mPhotoImage.__init__\u001b[1;34m(self, image, size, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__size \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__photo \u001b[38;5;241m=\u001b[39m \u001b[43mtkinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPhotoImage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__photo\u001b[38;5;241m.\u001b[39mtk\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\tkinter\\__init__.py:4129\u001b[0m, in \u001b[0;36mPhotoImage.__init__\u001b[1;34m(self, name, cnf, master, **kw)\u001b[0m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cnf\u001b[38;5;241m=\u001b[39m{}, master\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   4125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an image with NAME.\u001b[39;00m\n\u001b[0;32m   4126\u001b[0m \n\u001b[0;32m   4127\u001b[0m \u001b[38;5;124;03m    Valid resource names: data, format, file, gamma, height, palette,\u001b[39;00m\n\u001b[0;32m   4128\u001b[0m \u001b[38;5;124;03m    width.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4129\u001b[0m     \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mphoto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\tkinter\\__init__.py:4062\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, imgtype, name, cnf, master, **kw)\u001b[0m\n\u001b[0;32m   4060\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m master \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4062\u001b[0m     master \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_root\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4063\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(master, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtk\u001b[39m\u001b[38;5;124m'\u001b[39m, master)\n\u001b[0;32m   4064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\tkinter\\__init__.py:319\u001b[0m, in \u001b[0;36m_get_default_root\u001b[1;34m(what)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _default_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m what:\n\u001b[1;32m--> 319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo early to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: no default root window\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m     root \u001b[38;5;241m=\u001b[39m Tk()\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m _default_root \u001b[38;5;129;01mis\u001b[39;00m root\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Too early to create image: no default root window"
     ]
    }
   ],
   "source": [
    "# Load Haar Cascade for face detection (substitute with face detection for testing)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(gray, (28, 28))\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "    img_array = np.reshape(img_array, (1, 28, 28, 1))  # Reshape for the model input\n",
    "    return img_array\n",
    "\n",
    "def predict(img):\n",
    "    global current_symbol, word, blank_flag, str_text, ct\n",
    "\n",
    "    try:\n",
    "        result = loaded_model.predict(img)\n",
    "        if result.shape[1] != 26:  # Ensure the result has 26 elements for A-Z\n",
    "            raise ValueError(\"Unexpected model output shape\")\n",
    "\n",
    "        prediction = {\n",
    "            chr(65 + i): result[0][i] for i in range(26)\n",
    "        }\n",
    "\n",
    "        # Sort predictions in descending order\n",
    "        prediction = sorted(prediction.items(), key=lambda x: x[1], reverse=True)\n",
    "        current_symbol = prediction[0][0]\n",
    "        confidence = prediction[0][1] * 100  # Prediction percentage\n",
    "\n",
    "        # Update letter count and word\n",
    "        if current_symbol == \" \":\n",
    "            for i in ct:\n",
    "                ct[i] = 0\n",
    "        ct[current_symbol] += 1\n",
    "\n",
    "        if ct[current_symbol] > 60:\n",
    "            if current_symbol != \" \":\n",
    "                word += current_symbol\n",
    "            ct = {chr(i): 0 for i in range(65, 91)}\n",
    "\n",
    "        if current_symbol == \" \":\n",
    "            if blank_flag == 0:\n",
    "                blank_flag = 1\n",
    "                if len(str_text) > 0 and str_text[-1] != \" \":\n",
    "                    str_text += \" \"\n",
    "                str_text += word\n",
    "                word = \"\"\n",
    "        else:\n",
    "            blank_flag = 0\n",
    "\n",
    "        # Update GUI with the predictions\n",
    "        panel2.config(text=current_symbol, font=(\"Courier\", 50))\n",
    "        panel3.config(text=word, font=(\"Courier\", 40))\n",
    "        T.config(text=str_text, font=(\"Courier\", 40))\n",
    "\n",
    "        return confidence\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction: {e}\")\n",
    "        return 0\n",
    "\n",
    "def update_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.flip(frame, 1)  # Flip frame horizontally for a more natural selfie view\n",
    "\n",
    "        # Face detection (substitute with face detection as a fallback)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            confidence = 0\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            img_array = preprocess_frame(roi)\n",
    "            confidence = predict(img_array)  # Get prediction confidence\n",
    "\n",
    "            # Draw rectangle around detected face and put the confidence percentage\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"{current_symbol}: {confidence:.2f}%\",\n",
    "                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = Image.fromarray(img)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        panel.config(image=img_tk)\n",
    "        panel.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "\n",
    "    root.after(10, update_frame)  # Schedule next frame update\n",
    "\n",
    "update_frame()\n",
    "root.mainloop()\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
